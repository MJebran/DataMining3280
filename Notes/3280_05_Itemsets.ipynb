{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9467044-2d87-4593-ae76-2bd7d1f68ee6",
   "metadata": {},
   "source": [
    "# 05 Frequent Itemsets\n",
    "__Math 3280 - Data Mining__ : Snow College : Dr. Michael E. Olson\n",
    "\n",
    "* Leskovec, Chapter 6\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a338a9c-138f-44e8-966f-28579453a9a5",
   "metadata": {},
   "source": [
    "We learned earlier in the semester about how similar two objects may be to each other. We'll turn now to association between two kinds of objects. That is, there may not be any similarity between two objects, but there may be a relationship between them. For example, milk and bread are not very similar at all, but they are frequently bought together.\n",
    "\n",
    "A __market-basket__ model describes relationships between two kinds of objects. \n",
    "* *items*\n",
    "* *baskets* (sometimes called *transactions*) consist of an *itemset*\n",
    "    * We usually assume that the size of the itemset is much smaller than the total number of items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c45140-9bb8-44c3-b043-a71213474be8",
   "metadata": {},
   "source": [
    "## Frequent\n",
    "An itemset is said to be \"frequent\" if a subset of items appears in many baskets. Thinking of this mathematically, take an itemset $I$. \n",
    "* Define the __support__ of $I$ to be the number of baskets for which $I$ is a subset\n",
    "* $I$ is frequent if $Support(I) > s$ where $s$ is the __support threshold__\n",
    "\n",
    "Consider the following sets of letters:\n",
    "* {A, B, C}\n",
    "* {B, C, F}\n",
    "* {B, C, D}\n",
    "* {C, D, E}\n",
    "* {B, C, E}\n",
    "* {A, C, D}\n",
    "* {B, E, F}\n",
    "* {B, C, E}\n",
    "\n",
    "For this example, let's set our support threshold to $s = 5$.\n",
    "\n",
    "A __singleton set__ is a set of just one item. The supports for all the singleton sets are:\n",
    "$$Support(A) = 2 \\qquad Support(B) = 6 \\qquad Support(C) = 7 \\qquad Support(D) = 3 \\qquad Support(E) = 4 \\qquad Support(F) = 2$$\n",
    "\n",
    "From this, only items $B$ and $C$ are frequent, since they are greater than $s$.\n",
    "\n",
    "The support for the __doubleton__ subset $I_1 = \\{B, E\\}$ would be,\n",
    "\n",
    "$$Support(I_1) = \\text{\\# of times }\\{B,E\\}\\text{ appears} = 3$$\n",
    "\n",
    "If we have a support threshold of $s = 5$, then the set $I_1$ is not frequent.\n",
    "\n",
    "The support for the subset $I_2 = \\{B, C\\}$ would be,\n",
    "\n",
    "$$Support(I_2) = \\text{\\# of times }\\{B,C\\}\\text{ appears} = 5$$\n",
    "\n",
    "Thus $I_2$ is frequent.\n",
    "\n",
    "How can we use this information? Sometimes, the results of this calculation are useless. For example, the purchase of milk and eggs would be considered similar since they are often purchased together. However, hot dogs and mustard are not considered similar, but they would have a higher support. This opens a market tactic: offer a sale on hot dogs, but increase the price of mustard. When people buy hot dogs because they are on sale, they may say, \"Oh, I need mustard,\" and they'll get it regardless of the price.\n",
    "\n",
    "Common applications of frequent itemsets:\n",
    "1. *Related concepts*: words that often appear in conjunction with a topic. For example, how often does the word \"civil\" come up in an article about \"engineering\"\n",
    "2. *Plagiarism*: sentences that appear in different documents. A document that has a large number of sentences with high support may be indicative of a plagiarized document\n",
    "3. *Biomarkers*: genes or proteins appear when exposed to certain deseases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac353d-b876-467f-9c3e-ba7fe8e94323",
   "metadata": {},
   "source": [
    "## Association Rules\n",
    "Now, we want to look at how often different subsets appear together. A common application of this would be recommendation systems (\"customers who bought what is in your cart also bought [item]\"). To indicate the association of basket $I$ with item $j$ as $I\\to j$.\n",
    "\n",
    "So, how likely will basket $I$ be associated with $j$? We'll measure this be defining the __confidence__ of $I\\to j$ as,\n",
    "$$Confidence(I\\to j) = \\frac{Support(I\\cup \\{j\\})}{Support(I)}$$\n",
    "\n",
    "Using our earlier example, how likely is the set $I = \\{B, C\\}$ to be associated with $\\{E\\}$?\n",
    "$$Confidence(\\{B,C\\} \\to \\{E\\}) = \\frac{Support(\\{B, C, E\\})}{Support(\\{B, C\\})} = \\frac{2}{5}$$\n",
    "\n",
    "Another way to think of this: The set $\\{B,C\\}$ appears 5 times. Of those 5 times, $E$ appears twice.\n",
    "\n",
    "The confidence is useful as long as $Support(I)$ is fairly large. However, the confidence means more when the association rule reflects a true relationship. So, we define the __interest__ of an association rule as the difference between the confidence and the fraction of baskets that contain $j$.\n",
    "$$Interest(I\\to j) = Confidence(I\\to j) - \\frac{Support(\\{j\\})}{\\text{\\# of items}}$$\n",
    "\n",
    "The advantage to this is that if $I$ and $j$ aren't associated, then $Confidence(I\\to j) \\approx \\frac{Support(\\{j\\})}{\\text{\\# of items}}$, so $Interest(\\{B,C\\}\\to\\{E\\}) \\approx 0$\n",
    "\n",
    "Using our earlier example,\n",
    "$$Interest(\\{B,C\\}\\to\\{E\\}) = Confidence(\\{B,C\\} \\to \\{E\\}) - \\frac{Support(E)}{8}$$\n",
    "$$Interest(\\{B,C\\}\\to\\{E\\}) = \\frac{Support(\\{B, C, E\\})}{Support(\\{B, C\\})} - \\frac{Support(E)}{8} = \\frac{2}{5} - \\frac{4}{8} = -\\frac{1}{10}$$\n",
    "\n",
    "What do the numbers mean?\n",
    "* If the interest is high, then $I$ has a high probability of causing $j$\n",
    "* If the interest is highly negative, then $I$ has a high probability of discouraging $j$\n",
    "* If the interest is near 0, then any association between $I$ and $j$ is likely coincidental\n",
    "\n",
    "How does this compare with others? Find the Confidence and Interest of $\\{A,B\\}\\to\\{C\\}$, $\\{B,F\\}\\to\\{E\\}$, $\\{C,D\\}\\to\\{A\\}$, and $\\{B,C\\}\\to\\{F\\}$.\n",
    "$$Confidence(\\{A,B\\}\\to\\{C\\}) = \\frac{1}{1} \\qquad Interest(\\{A,B\\}\\to\\{C\\}) = 1 - \\frac{7}{8} = \\frac{1}{8} = 0.125$$\n",
    "$$Confidence(\\{B,F\\}\\to\\{E\\}) = \\frac{1}{2} \\qquad Interest(\\{B,F\\}\\to\\{E\\}) = \\frac{1}{2} - \\frac{4}{8} = 0\\qquad\\qquad$$\n",
    "$$Confidence(\\{C,D\\}\\to\\{A\\}) = \\frac{1}{3} \\qquad Interest(\\{C,D\\}\\to\\{A\\}) = \\frac{1}{3} - \\frac{2}{8} = \\frac{1}{12} = 0.0833$$\n",
    "$$Confidence(\\{B,C\\}\\to\\{F\\}) = \\frac{1}{4} \\qquad Interest(\\{B,C\\}\\to\\{F\\}) = \\frac{1}{4} - \\frac{2}{8} = 0\\qquad\\qquad$$\n",
    "\n",
    "With large datasets, a \"reasonably high\" interest would be items in 1\\% of the baskets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae9d81-a6f0-4f31-8bc1-08a35f367ad6",
   "metadata": {},
   "source": [
    "## A-Priori Algorithm\n",
    "This method is not too difficult. However, as is always the problem in the real world, we are dealing with very large amounts of data that can't always be held in main memory, much less do calculations with them. So, to simplify the process, we'll look at the __A-Priori__ algorithm, which only looks at the most frequent items.\n",
    "\n",
    "In order to understand the A-Priori algorithm, there are a few mathematical methods that need to be implemented. We won't go over these here. But they are in section 6.2.2 of the *Leskovec* textbook.\n",
    "\n",
    "The basic principle of the A-Priori is to decrease the number of calculations. But in order to do this, we make 2 passes through the data instead of just 1.\n",
    "\n",
    "__Pass 1__: Go through the data and count the frequency of each item\n",
    "* Select only the items with a support over the support threshold (again, often around 1\\%)\n",
    "* Begin with a list of $n$ items, narrow that down to $m$ items, where $m$ is a small fraction of $n$.\n",
    "\n",
    "__Pass 2__: For each basket, find only frequent items and count the pairs. Count all pairs for all baskets.\n",
    "\n",
    "If 50\\% of the items are eliminated, then since we are dealing with pairs, there will only be 25\\% of the calculations. This saves a lot on time and memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7b6c9-0518-44d4-b813-cc985e0bcb22",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1f348a1-a530-4278-b86b-07dabac479f2",
   "metadata": {},
   "source": [
    "--------\n",
    "## Homework\n",
    "* Exercise 6.1.1 a,b,c\n",
    "* Exercise 6.1.2\n",
    "* Exercise 6.1.5 a,b - Find both the confidence and the interest of each association rule\n",
    "* Exercise 6.1.7 a\n",
    "* Exercise 6.2.6 a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd37974-a50c-459f-a6a9-d1d6a6c524d6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
